<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>震撼来袭！本地部署最强开源视觉大模型 Qwen2.5-VL 的神奇体验 | lijianfei.com</title>
<link rel="shortcut icon" href="https://lijianfei.com/favicon.ico?v=1761120781074">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://lijianfei.com/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="震撼来袭！本地部署最强开源视觉大模型 Qwen2.5-VL 的神奇体验 | lijianfei.com - Atom Feed" href="https://lijianfei.com/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">
<script id="chatway" async="true" src="https://cdn.chatway.app/widget.js?id=laNLrbQJYsup"></script>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5152652314157130"
     crossorigin="anonymous">
</script>

<script type="text/javascript">
    (function(c,l,a,r,i,t,y){
        c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
        t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
        y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
    })(window, document, "clarity", "script", "m0j4678d23");
</script>
     


<script async src="https://www.googletagmanager.com/gtag/js?id=UA-74398720-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-74398720-1');
</script>


    <meta property="og:title" content="震撼来袭！本地部署最强开源视觉大模型 Qwen2.5-VL 的神奇体验">
    <meta property="og:description" content="大家好，今天我将带领大家深入了解如何在自己的电脑上本地部署这款被誉为“最强开源视觉大模型”的 Qwen2.5-VL，让大家亲身感受它所带来的震撼体验。

一、Qwen2.5-VL：重新定义视觉AI的天花板
最近，Qwen 推出了全新的旗舰视...">
    <meta property="og:type" content="AI">
    <meta property="og:url" content="https://lijianfei.com/post/zhen-han-lai-xi-ben-di-bu-shu-zui-qiang-kai-yuan-shi-jue-da-mo-xing-qwen25-vl-de-shen-qi-ti-yan/">
    <meta property="og:image" content="https://cdn.jsdelivr.net/gh/lijianfeigeek/PictureBed@20241223/uPic/a8uOP0.png"/>
    <meta property="og:image:width" content="800">
    <meta property="og:image:height" content="500">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@lijianfei_com">
    <meta name="twitter:title" content="震撼来袭！本地部署最强开源视觉大模型 Qwen2.5-VL 的神奇体验">
    <meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/lijianfeigeek/PictureBed@20241223/uPic/a8uOP0.png">
    <meta name="twitter:image:width" content="800">

    <meta name="description" content="大家好，今天我将带领大家深入了解如何在自己的电脑上本地部署这款被誉为“最强开源视觉大模型”的 Qwen2.5-VL，让大家亲身感受它所带来的震撼体验。

一、Qwen2.5-VL：重新定义视觉AI的天花板
最近，Qwen 推出了全新的旗舰视..." />
    <meta name="keywords" content="AI" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://lijianfei.com">
  <img class="avatar" src="https://lijianfei.com/images/avatar.png?v=1761120781074" alt="">
  </a>
  <h1 class="site-title">
    lijianfei.com
  </h1>
  <p class="site-description">
    思危，思退，思变。<br>
追求进步，不求完美。<br>
做好小事，熬过难事，静成大事。<br>
语以泄败，事以密成，沉得住气，静得下心。
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于我
        </a>
      
    
      
        <a href="https://github.com/lijianfeigeek" class="menu" target="_blank">
          Github
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
    <img src="https://ghchart.rshah.org/F15406/lijianfeigeek" style="max-width: 100%;height: auto;"/>
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              震撼来袭！本地部署最强开源视觉大模型 Qwen2.5-VL 的神奇体验
            </h2>
            <div class="post-info">
              <span>
                2025-02-15
              </span>
              <span>
                7 min read
              </span>
              
                <a href="https://lijianfei.com/tag/ai/" class="post-tag">
                  # AI
                </a>
              
            </div>
            
              <img class="post-feature-image" src="https://cdn.jsdelivr.net/gh/lijianfeigeek/PictureBed@20241223/uPic/a8uOP0.png" alt="">
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <p>大家好，今天我将带领大家深入了解如何在自己的电脑上本地部署这款被誉为“最强开源视觉大模型”的 Qwen2.5-VL，让大家亲身感受它所带来的震撼体验。</p>
<!-- more -->
<h2 id="一-qwen25-vl重新定义视觉ai的天花板"><strong>一、Qwen2.5-VL：重新定义视觉AI的天花板</strong></h2>
<p>最近，Qwen 推出了全新的旗舰视觉语言模型——Qwen2.5-VL。这个版本相较于之前的 Qwen2.0 VL 有着质的飞跃，不仅在图像识别方面表现出色，还能精准分析图片中的复杂文本、图表、图形和布局等，堪称多模态 AI 的新标杆。</p>
<p>更让人惊喜的是，Qwen2.5-VL 是完全免费且开源的！这意味着每个人都可以轻松下载并部署它。无论你是技术大牛还是小白用户，都能在这个平台上找到属于自己的乐趣。</p>
<p>目前，Qwen2.5-VL 提供了三个不同的模型尺寸：3B、7B 和 72B。每个版本都有其独特的优势：</p>
<ol>
<li>
<p><strong>3B 模型</strong>：虽然体积最小，但它却是个潜力无限的“小钢炮”。它甚至可以直接在手机上运行，性能远超之前的 VL 版本。</p>
</li>
<li>
<p><strong>7B 模型</strong>：适合大多数用户的显卡配置，性能强劲且稳定。</p>
</li>
<li>
<p><strong>72B 模型</strong>：土豪专属！这个版本简直就是为专业级别的 GPU 设计的，性能直接拉满，堪称视觉 AI 的天花板。</p>
</li>
</ol>
<p>在最新的视觉模型基准测试中，Qwen2.5-VL 几乎在所有任务上都表现得无可挑剔，甚至全面超越了 GPT-4、Claude 3.5 和 Gemini 2.0 等一众明星模型。即使是中型的 7B 模型，也在多个任务中轻松碾压 GPT-4 Mini。可以说，Qwen2.5-VL 的出现，重新定义了视觉 AI 的标准。</p>
<h2 id="二-本地部署-qwen25-vl手把手教学"><strong>二、本地部署 Qwen2.5-VL：手把手教学</strong></h2>
<p>接下来，我们将一步步教大家如何在自己的电脑上实现 Qwen2.5-VL 的本地部署。无论是为了体验它的强大功能，还是为了进行二次开发，这都将是一个非常有趣的过程。</p>
<h3 id="第一步环境搭建"><strong>第一步：环境搭建</strong></h3>
<ol>
<li>
<p><strong>安装 Python</strong><br>
首先，你需要确保你的电脑上已经安装了 Python 环境。推荐使用 Python 3.10.6 版本。如果你还没有安装，可以从官网下载。记得在安装时勾选“将 Python 添加到 PATH”这个选项，否则后续可能会遇到各种麻烦。</p>
</li>
<li>
<p><strong>安装 Git</strong><br>
接下来，安装 Git 工具。Git 是版本控制系统中的“老大哥”，几乎每个开发者都在使用它。安装完成后，你就可以通过 Git 来克隆 Qwen2.5-VL 的开源仓库了。</p>
</li>
</ol>
<h3 id="第二步克隆开源仓库"><strong>第二步：克隆开源仓库</strong></h3>
<p>打开终端（Windows 用户可以用 CMD 或 PowerShell），输入以下命令：</p>
<pre><code class="language-bash">git clone https://github.com/Qwen-AI/Qwen2.5-VL.git
</code></pre>
<p>这将下载 Qwen2.5-VL 的最新版本到你的电脑上。整个过程可能需要几分钟，具体取决于你的网络速度。</p>
<h3 id="第三步安装依赖包"><strong>第三步：安装依赖包</strong></h3>
<p>进入克隆下来的文件夹，运行以下命令来安装模型所需的依赖包：</p>
<pre><code class="language-bash">pip install -r requirements.txt
</code></pre>
<p>这个过程可能会比较漫长，因为需要下载大量的第三方库。如果你的网络在国外，建议提前做好科学上网的准备。</p>
<h3 id="第四步安装支持-cuda-的-pytorch"><strong>第四步：安装支持 CUDA 的 PyTorch</strong></h3>
<p>为了充分发挥 Qwen2.5-VL 的性能，我们推荐使用支持 CUDA 的版本。运行以下命令：</p>
<pre><code class="language-bash">pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu117
</code></pre>
<p>如果你的显卡不支持 CUDA，也可以安装 CPU 版本，但性能会大打折扣。</p>
<h3 id="第五步下载模型"><strong>第五步：下载模型</strong></h3>
<p>根据你的硬件配置选择合适的模型版本：</p>
<ul>
<li>对于笔记本电脑或显存小于 8GB 的用户，建议选择 3B 模型。</li>
<li>如果你的显存大于等于 8GB，那么 7B 模型将是一个更好的选择。<br>
-土豪专属的 72B 模型则需要至少 24GB 的显存。</li>
</ul>
<p>下载模型后，将其解压到指定目录即可。整个过程可能会消耗较多的网络流量，建议使用 Wi-Fi 进行操作。</p>
<h3 id="第六步启动本地服务"><strong>第六步：启动本地服务</strong></h3>
<p>运行以下命令启动 Gradio 界面：</p>
<pre><code class="language-bash">python main.py
</code></pre>
<p>稍等片刻，你就会看到一个本地链接（如 <code>http://localhost:7860</code>）。在浏览器中打开这个链接，就可以开始体验 Qwen2.5-VL 的强大功能了。</p>
<h2 id="三-实战体验qwen25-vl-能做什么"><strong>三、实战体验：Qwen2.5-VL 能做什么？</strong></h2>
<h3 id="1-图片识别与分析"><strong>1. 图片识别与分析</strong></h3>
<p>无论是判断一张图片是真人拍摄还是 AI 生成的，还是分析图片中的人物特征，Qwen2.5-VL 都能给出令人惊叹的答案。例如，你上传一张风景照，它不仅能准确识别出地理位置，还能分析出图片中的具体元素。</p>
<h3 id="2-视频理解"><strong>2. 视频理解</strong></h3>
<p>得益于强大的多模态能力，Qwen2.5-VL 还支持对长视频的分析。即使是超过一小时的视频内容，它也能轻松处理。</p>
<h3 id="3-营销助力封面点击率预测"><strong>3. 营销助力：封面点击率预测</strong></h3>
<p>对于从事营销工作的朋友来说，Qwen2.5-VL 的另一个强大功能就是帮助你选择最佳的视频封面。通过上传多个候选图片，它可以精准预测哪一张更具吸引力，从而提高你的视频点击率。</p>
<h2 id="四-官方免费平台无需本地部署也能玩转-qwen25-vl"><strong>四、官方免费平台：无需本地部署也能玩转 Qwen2.5-VL</strong></h2>
<p>如果你觉得本地部署有些麻烦，或者硬件配置不够，完全可以通过 Qwen 官方提供的免费在线平台来体验 Qwen2.5-VL 的强大功能。虽然这些平台使用的是共享 GPU，但在大多数情况下已经足够满足需求。</p>
<p>通过注册一个账号（支持邮箱、Google 账号或 GitHub 账号登录），你就可以直接使用包括 72B 模型在内的所有版本。无论是图像生成、视觉分析还是复杂的推理任务，官方平台都能轻松应对。</p>
<h2 id="五-总结与展望"><strong>五、总结与展望</strong></h2>
<p>Qwen2.5-VL 的出现，无疑为开源 AI 领域注入了一剂强心针。它不仅让我们看到了多模态 AI 的无限可能，也为普通用户提供了接触前沿科技的窗口。</p>
<p>如果你对 AI 技术感兴趣，不妨动手尝试一下本地部署 Qwen2.5-VL，亲身体验它带来的惊喜与乐趣。相信在不久的将来，开源视觉大模型将会在更多领域发挥出巨大的价值。</p>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#%E4%B8%80-qwen25-vl%E9%87%8D%E6%96%B0%E5%AE%9A%E4%B9%89%E8%A7%86%E8%A7%89ai%E7%9A%84%E5%A4%A9%E8%8A%B1%E6%9D%BF"><strong>一、Qwen2.5-VL：重新定义视觉AI的天花板</strong></a></li>
<li><a href="#%E4%BA%8C-%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2-qwen25-vl%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E5%AD%A6"><strong>二、本地部署 Qwen2.5-VL：手把手教学</strong></a>
<ul>
<li><a href="#%E7%AC%AC%E4%B8%80%E6%AD%A5%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA"><strong>第一步：环境搭建</strong></a></li>
<li><a href="#%E7%AC%AC%E4%BA%8C%E6%AD%A5%E5%85%8B%E9%9A%86%E5%BC%80%E6%BA%90%E4%BB%93%E5%BA%93"><strong>第二步：克隆开源仓库</strong></a></li>
<li><a href="#%E7%AC%AC%E4%B8%89%E6%AD%A5%E5%AE%89%E8%A3%85%E4%BE%9D%E8%B5%96%E5%8C%85"><strong>第三步：安装依赖包</strong></a></li>
<li><a href="#%E7%AC%AC%E5%9B%9B%E6%AD%A5%E5%AE%89%E8%A3%85%E6%94%AF%E6%8C%81-cuda-%E7%9A%84-pytorch"><strong>第四步：安装支持 CUDA 的 PyTorch</strong></a></li>
<li><a href="#%E7%AC%AC%E4%BA%94%E6%AD%A5%E4%B8%8B%E8%BD%BD%E6%A8%A1%E5%9E%8B"><strong>第五步：下载模型</strong></a></li>
<li><a href="#%E7%AC%AC%E5%85%AD%E6%AD%A5%E5%90%AF%E5%8A%A8%E6%9C%AC%E5%9C%B0%E6%9C%8D%E5%8A%A1"><strong>第六步：启动本地服务</strong></a></li>
</ul>
</li>
<li><a href="#%E4%B8%89-%E5%AE%9E%E6%88%98%E4%BD%93%E9%AA%8Cqwen25-vl-%E8%83%BD%E5%81%9A%E4%BB%80%E4%B9%88"><strong>三、实战体验：Qwen2.5-VL 能做什么？</strong></a>
<ul>
<li><a href="#1-%E5%9B%BE%E7%89%87%E8%AF%86%E5%88%AB%E4%B8%8E%E5%88%86%E6%9E%90"><strong>1. 图片识别与分析</strong></a></li>
<li><a href="#2-%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3"><strong>2. 视频理解</strong></a></li>
<li><a href="#3-%E8%90%A5%E9%94%80%E5%8A%A9%E5%8A%9B%E5%B0%81%E9%9D%A2%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E6%B5%8B"><strong>3. 营销助力：封面点击率预测</strong></a></li>
</ul>
</li>
<li><a href="#%E5%9B%9B-%E5%AE%98%E6%96%B9%E5%85%8D%E8%B4%B9%E5%B9%B3%E5%8F%B0%E6%97%A0%E9%9C%80%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B9%9F%E8%83%BD%E7%8E%A9%E8%BD%AC-qwen25-vl"><strong>四、官方免费平台：无需本地部署也能玩转 Qwen2.5-VL</strong></a></li>
<li><a href="#%E4%BA%94-%E6%80%BB%E7%BB%93%E4%B8%8E%E5%B1%95%E6%9C%9B"><strong>五、总结与展望</strong></a></li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://lijianfei.com/post/ying-wei-da-qing-cang-huan-gu-mei-gu-shi-chang-shang-yan-xie-xi-yu-bao-zhang-de-shuang-chong-xi-ma/">
              <h3 class="post-title">
                英伟达清仓换股，美股市场上演“血洗”与“暴涨”的双重戏码！
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://lijianfei.com/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
